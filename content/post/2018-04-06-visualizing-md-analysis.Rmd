---
title: Visualizing Multi-Dimensional Analysis
author: Geoff LaFlair
date: '2018-04-06'
slug: an-attempt-at-making-laflair-staples-2017-more-dynamic
categories: []
tags: []
draft: true
output:
  blogdown::html_page:
    toc: true
    number_sections: true
    toc_depth: 1
---

On April 6, 2018, I read notice the following tweet from Miles McBain. The linked article [The Scientific Paper is Obsolete](https://www.theatlantic.com/science/archive/2018/04/the-scientific-paper-is-obsolete/556676/) makes a great argument for the inclusion of computers and computational tools in the dissemination of research. 

The TL;DR version of the article is that since the printing press, researchers have been sharing the result of their research using the same method--paper. James Somers (the author) argues (rightfully) that a pdf is just an electronic version of a piece of paper, and that the computational tools that are available enable researchers to "show" their research in a manner that would (hopefully) help people better understand the analysis, results, and interpretation of the results. The [example](http://worrydream.com/ScientificCommunicationAsSequentialArt/) he links to in article does this for a paper that investigated collective dynamics using networks, which effectively implements some of [these](http://worrydream.com/ExplorableExplanations/) ideas for interactive scientific communication.

```{r, echo = FALSE}
blogdown::shortcode('tweet', '982382059569082369')
```

This got me thinking about multidimensional analysis of language data. I think that this can be a difficult concept to understand on paper. So this is my attempt to make a supplemental report of LaFlair & [Staples](https://english.arizona.edu/users/shelley-staples) (2018) that includes the use of more interactivity in explaining the analysis and describing the results of our study.

In this paper, we compared test takers' language from a speaking assessment to how language is used in other domains (i.e., nurse-patient interactions, service encounters, office hours, conversation). The point of this exercise is to see if language use from the test overlaps with language use in the domains. This is important because tests such as these are used to make decisions (e.g., nursing certification, admission to university) about the test takers performance in the other domains. The more overlap there is in how language is used on the test and how language is used in the other domains the stronger the evidence for making interpretations about test taker ability in the other domains.

To accomplish this, we used what [Doug Biber](https://dougbiber.weebly.com/) calls "multi-dimensional analysis" or MD analysis. This process allows researchers reduce large amounts of linguistic data to smaller sets of communicatively interpretable variables.

```{r, echo=FALSE, message=FALSE, error=FALSE, warning=FALSE}
library(tidyverse)
library(ggridges)
library(viridis)

LT_data <- read_csv('data/LT_data.csv', col_types = 'ccciddidddddcci') 
vars <- read_csv('data/variables_for_factor_analysis.csv')

ling_feat <- vars %>%
  # select(., -word_count) %>%
  gather(., key, value, -corpus, -file, -SpeakGrp) %>%
  mutate(SpeakGrp = factor(SpeakGrp),
         key = factor(key)) %>%
  ggplot(., aes(x = value, y = SpeakGrp, fill = SpeakGrp)) +
  # geom_density_ridges(aes(point_color = SpeakGrp, point_fill = SpeakGrp,
  #                         point_shape = SpeakGrp),
  #                     alpha = .2, jittered_points = TRUE) +
  geom_density_ridges()+
  # scale_discrete_manual(aesthetics = "point_shape", values = c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10)) +
  facet_wrap(~ key, scales = 'free') +
  ggtitle('Distributions of Linguistic Features in Corpora', subtitle = 'per 1,000 words') 
```


